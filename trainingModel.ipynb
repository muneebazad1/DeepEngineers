{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.signal as signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------------------------------\n",
        "# 1. Preprocessing Functions\n",
        "# -------------------------------------------\n",
        "def bandpass_filter(ecg_signal, lowcut=0.5, highcut=40, fs=500, order=4):\n",
        "    \"\"\"Applies a Butterworth band-pass filter to the ECG signal.\"\"\"\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = signal.butter(order, [low, high], btype='band', analog=False)\n",
        "    filtered_ecg = signal.filtfilt(b, a, ecg_signal)\n",
        "    return filtered_ecg\n",
        "\n",
        "def downsample_signal(ecg_signal, factor=5):\n",
        "    \"\"\"Downsamples the signal by taking every 'factor'-th sample.\n",
        "       For a 5000-point signal, factor=5 reduces it to 1000 points.\"\"\"\n",
        "    return ecg_signal[::factor]\n",
        "\n",
        "def frame_ecg(ecg_signal, frame_size=1000):\n",
        "    \"\"\"\n",
        "    Ensures the ECG signal is exactly frame_size long.\n",
        "    Expects a 1D array; if shorter, pads with zeros; if longer, truncates.\n",
        "    \"\"\"\n",
        "    n_points = ecg_signal.shape[0]\n",
        "    if n_points < frame_size:\n",
        "        padded = np.zeros(frame_size, dtype=ecg_signal.dtype)\n",
        "        padded[:n_points] = ecg_signal\n",
        "        return padded\n",
        "    else:\n",
        "        return ecg_signal[:frame_size]\n",
        "\n",
        "# -------------------------------------------\n",
        "# 2. Functions to Handle .hea Files and Build Label Mapping\n",
        "# -------------------------------------------\n",
        "def read_hea_file(hea_path):\n",
        "    \"\"\"\n",
        "    Reads a .hea file and extracts diagnostic codes.\n",
        "    Assumes a line starting with '#Dx:' contains the diagnostic codes.\n",
        "    \"\"\"\n",
        "    diagnostic_codes = []\n",
        "    with open(hea_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#Dx:'):\n",
        "                codes_line = line.strip()[4:].strip()  # Remove \"#Dx:\" prefix\n",
        "                codes = codes_line.replace(',', ' ').split()\n",
        "                diagnostic_codes.extend(codes)\n",
        "                break\n",
        "    return diagnostic_codes\n",
        "\n",
        "def build_diagnostic_mapping(hea_files):\n",
        "    \"\"\"Builds a mapping from diagnostic code to index using all provided .hea files.\"\"\"\n",
        "    all_codes = set()\n",
        "    for hea_file in hea_files:\n",
        "        codes = read_hea_file(hea_file)\n",
        "        all_codes.update(codes)\n",
        "    sorted_codes = sorted(list(all_codes))\n",
        "    mapping = {code: idx for idx, code in enumerate(sorted_codes)}\n",
        "    return mapping\n",
        "\n",
        "# -------------------------------------------\n",
        "# 3. File Pairing\n",
        "# -------------------------------------------\n",
        "def get_file_pairs(data_dir):\n",
        "    \"\"\"\n",
        "    Scans the directory for .mat files and returns a list of tuples:\n",
        "    (mat_file_path, corresponding hea_file_path).\n",
        "    \"\"\"\n",
        "    mat_files = glob.glob(os.path.join(data_dir, \"*.mat\"))\n",
        "    file_pairs = []\n",
        "    for mat_file in mat_files:\n",
        "        base = os.path.splitext(mat_file)[0]\n",
        "        hea_file = base + \".hea\"\n",
        "        if os.path.exists(hea_file):\n",
        "            file_pairs.append((mat_file, hea_file))\n",
        "    return file_pairs\n",
        "\n",
        "# -------------------------------------------\n",
        "# 4. Data Generator Function for tf.data\n",
        "# -------------------------------------------\n",
        "def data_generator(file_pairs, diag_mapping, frame_size=1000, fs=500):\n",
        "    \"\"\"\n",
        "    Generator function that yields preprocessed ECG signals and corresponding multi-label vectors.\n",
        "    For multi-lead signals, each lead is processed and then combined so that the final signal has\n",
        "    shape (frame_size, num_leads).\n",
        "    \"\"\"\n",
        "    num_classes = len(diag_mapping)\n",
        "    for mat_path, hea_path in file_pairs:\n",
        "        # Load raw signal from .mat file (assuming key 'val')\n",
        "        mat_contents = loadmat(mat_path)\n",
        "        raw_signal = mat_contents['val']\n",
        "        raw_signal = np.squeeze(raw_signal)\n",
        "        # If the signal is 1D, convert to 2D with one channel.\n",
        "        if raw_signal.ndim == 1:\n",
        "            raw_signal = np.expand_dims(raw_signal, axis=0)\n",
        "        # raw_signal shape: (num_leads, 5000)\n",
        "        num_leads = raw_signal.shape[0]\n",
        "        processed_leads = []\n",
        "        for i in range(num_leads):\n",
        "            lead = raw_signal[i]\n",
        "            filtered_signal = bandpass_filter(lead, fs=fs)\n",
        "            downsampled_signal = downsample_signal(filtered_signal, factor=5)\n",
        "            framed_signal = frame_ecg(downsampled_signal, frame_size=frame_size)\n",
        "            processed_leads.append(framed_signal)\n",
        "        # Stack and transpose: final shape becomes (frame_size, num_leads)\n",
        "        processed_leads = np.stack(processed_leads, axis=0)\n",
        "        final_signal = processed_leads.transpose(1, 0).astype(np.float32)\n",
        "\n",
        "        # Process diagnostic codes from .hea file into a multi-label vector\n",
        "        codes = read_hea_file(hea_path)\n",
        "        label_vector = np.zeros(num_classes, dtype=np.float32)\n",
        "        for code in codes:\n",
        "            if code in diag_mapping:\n",
        "                label_vector[diag_mapping[code]] = 1.0\n",
        "\n",
        "        yield final_signal, label_vector\n",
        "\n",
        "# -------------------------------------------\n",
        "# 5. Custom Keras Layers: BasicResBlock and Attention\n",
        "# -------------------------------------------\n",
        "class BasicResBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, out_channels, kernel_size=7, strides=1, **kwargs):\n",
        "        super(BasicResBlock, self).__init__(**kwargs)\n",
        "        self.conv1 = tf.keras.layers.Conv1D(out_channels, kernel_size, strides=strides, padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "        self.conv2 = tf.keras.layers.Conv1D(out_channels, kernel_size, strides=strides, padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.downsample = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if input_shape[-1] != self.conv1.filters:\n",
        "            self.downsample = tf.keras.Sequential([\n",
        "                tf.keras.layers.Conv1D(self.conv1.filters, kernel_size=1, padding='same'),\n",
        "                tf.keras.layers.BatchNormalization()\n",
        "            ])\n",
        "        super(BasicResBlock, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        residual = inputs\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(inputs, training=training)\n",
        "        x = self.relu(x + residual)\n",
        "        return x\n",
        "\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        self.attention_dense = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs shape: (batch, timesteps, features)\n",
        "        scores = self.attention_dense(inputs)  # (batch, timesteps, 1)\n",
        "        weights = tf.nn.softmax(scores, axis=1)  # softmax along time dimension\n",
        "        weighted_sum = tf.reduce_sum(inputs * weights, axis=1)  # (batch, features)\n",
        "        return weighted_sum\n",
        "\n",
        "# -------------------------------------------\n",
        "# 6. Model Definition\n",
        "# -------------------------------------------\n",
        "def build_model(num_classes, frame_size=1000, num_leads=12, res_channels=32, lstm_hidden=128, num_layers=1):\n",
        "    \"\"\"\n",
        "    Constructs a model with:\n",
        "      - Two ResNet-like blocks for feature extraction.\n",
        "      - AveragePooling to reduce the time dimension.\n",
        "      - A bidirectional LSTM to capture temporal dependencies.\n",
        "      - An attention layer to focus on informative time steps.\n",
        "      - A Dense layer for multi-label classification.\n",
        "    The model now accepts inputs of shape (frame_size, num_leads).\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(frame_size, num_leads))\n",
        "\n",
        "    # ResNet-like blocks\n",
        "    x = BasicResBlock(res_channels, kernel_size=7)(inputs)\n",
        "    x = BasicResBlock(res_channels * 2, kernel_size=7)(x)\n",
        "\n",
        "    # Reduce time dimension: from frame_size -> frame_size//10 (pool_size 10)\n",
        "    x = tf.keras.layers.AveragePooling1D(pool_size=10, strides=10)(x)\n",
        "\n",
        "    # BiLSTM layers: stacking multiple layers if num_layers > 1\n",
        "    for _ in range(num_layers):\n",
        "        x = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(lstm_hidden, return_sequences=True)\n",
        "        )(x)\n",
        "\n",
        "    # Attention mechanism\n",
        "    x = Attention()(x)\n",
        "\n",
        "    # Final classification layer (logits output; use from_logits=True in loss)\n",
        "    outputs = tf.keras.layers.Dense(num_classes)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# -------------------------------------------\n",
        "# 7. Main Function: Data Loading, Model Training, and Saving\n",
        "# -------------------------------------------\n",
        "def main():\n",
        "    # Set your data directory containing .mat and .hea files\n",
        "    data_dir = \"/Users/Dell/Desktop/Data100\"  # Replace with your actual data folder path\n",
        "    file_pairs = get_file_pairs(data_dir)\n",
        "    if not file_pairs:\n",
        "        print(\"No file pairs found in the specified directory.\")\n",
        "        return\n",
        "\n",
        "    # Build diagnostic mapping from all .hea files\n",
        "    hea_files = [pair[1] for pair in file_pairs]\n",
        "    diag_mapping = build_diagnostic_mapping(hea_files)\n",
        "    print(\"Diagnostic Mapping:\", diag_mapping)\n",
        "\n",
        "    # Split file pairs into training and validation sets\n",
        "    train_pairs, val_pairs = train_test_split(file_pairs, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Parameters\n",
        "    frame_size = 1000\n",
        "    fs = 500\n",
        "    num_classes = len(diag_mapping)\n",
        "    batch_size = 8\n",
        "    num_epochs = 100\n",
        "\n",
        "    # Create tf.data Datasets from generator\n",
        "    train_dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(train_pairs, diag_mapping, frame_size, fs),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(frame_size, None), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n",
        "        )\n",
        "    )\n",
        "    val_dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(val_pairs, diag_mapping, frame_size, fs),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(frame_size, None), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Note: The second dimension in the TensorSpec (None) will be inferred from the data (should be num_leads).\n",
        "    # Optionally, if you know you always have 12 leads, you can set shape=(frame_size, 12).\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=100).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Determine number of leads from the first sample\n",
        "    for sample, _ in train_dataset.take(1):\n",
        "        num_leads = sample.shape[-1]\n",
        "    print(\"Number of leads detected:\", num_leads)\n",
        "\n",
        "    # Build the model with the detected number of leads\n",
        "    model = build_model(num_classes, frame_size=frame_size, num_leads=num_leads,\n",
        "                        res_channels=16, lstm_hidden=64, num_layers=1)\n",
        "    model.summary()\n",
        "\n",
        "    # Compile the model with binary cross-entropy loss (from_logits=True)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_dataset,\n",
        "              epochs=num_epochs,\n",
        "              validation_data=val_dataset)\n",
        "\n",
        "    # Save the model\n",
        "    model.save(\"/Users/Dell/Desktop/repository/updated_ecg_multilabel_model_tf.h5\")\n",
        "    print(\"Model saved as ecg_multilabel_model_tf.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5IPYm2CgOulC",
        "outputId": "3abf5b09-340c-40e1-ae51-abfd4179ba83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnostic Mapping: {'10370003': 0, '106068003': 1, '111288001': 2, '11157007': 3, '111975006': 4, '13640000': 5, '164865005': 6, '164873001': 7, '164889003': 8, '164890007': 9, '164896001': 10, '164909002': 11, '164912004': 12, '164917005': 13, '164930006': 14, '164931005': 15, '164934002': 16, '164937009': 17, '164942001': 18, '164947007': 19, '17338001': 20, '17366009': 21, '195042002': 22, '195060002': 23, '195101003': 24, '233892002': 25, '233897008': 26, '233917008': 27, '251120003': 28, '251146004': 29, '251164006': 30, '251166008': 31, '251170000': 32, '251173003': 33, '251180001': 34, '251187003': 35, '251198002': 36, '251199005': 37, '251205003': 38, '251223006': 39, '270492004': 40, '27885002': 41, '284470004': 42, '29320008': 43, '365413008': 44, '39732003': 45, '418818005': 46, '425856008': 47, '426177001': 48, '426183003': 49, '426627000': 50, '426648003': 51, '426664006': 52, '426761007': 53, '426783006': 54, '426995002': 55, '427084000': 56, '427172004': 57, '427393009': 58, '428417006': 59, '428750005': 60, '429622005': 61, '445118002': 62, '445211001': 63, '446358003': 64, '446813000': 65, '47665007': 66, '49578007': 67, '50799005': 68, '54016002': 69, '54329005': 70, '55827005': 71, '55930002': 72, '5609005': 73, '57054005': 74, '59118001': 75, '59931005': 76, '61277005': 77, '61721007': 78, '63593006': 79, '6374002': 80, '65778007': 81, '67741000119109': 82, '67751000119106': 83, '698252002': 84, '713422000': 85, '713426002': 86, '713427006': 87, '733534002': 88, '74390002': 89, '75532003': 90, '77867006': 91, '81898007': 92, '89792004': 93}\n",
            "Number of leads detected: 12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ basic_res_block_4 (\u001b[38;5;33mBasicResBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │           \u001b[38;5;34m3,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ basic_res_block_5 (\u001b[38;5;33mBasicResBlock\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │          \u001b[38;5;34m11,744\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling1d_2                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m49,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m)                  │          \u001b[38;5;34m12,126\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ basic_res_block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BasicResBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ basic_res_block_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BasicResBlock</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,744</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling1d_2                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,126</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,231\u001b[0m (301.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,231</span> (301.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,943\u001b[0m (300.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,943</span> (300.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 135ms/step - binary_accuracy: 0.9621 - loss: 0.1980 - val_binary_accuracy: 0.9636 - val_loss: 0.1228\n",
            "Epoch 2/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9632 - loss: 0.1240 - val_binary_accuracy: 0.9638 - val_loss: 0.1195\n",
            "Epoch 3/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 126ms/step - binary_accuracy: 0.9637 - loss: 0.1196 - val_binary_accuracy: 0.9641 - val_loss: 0.1141\n",
            "Epoch 4/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9639 - loss: 0.1137 - val_binary_accuracy: 0.9646 - val_loss: 0.1090\n",
            "Epoch 5/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9646 - loss: 0.1086 - val_binary_accuracy: 0.9650 - val_loss: 0.1050\n",
            "Epoch 6/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9656 - loss: 0.1037 - val_binary_accuracy: 0.9660 - val_loss: 0.1004\n",
            "Epoch 7/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9662 - loss: 0.0996 - val_binary_accuracy: 0.9664 - val_loss: 0.0992\n",
            "Epoch 8/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9669 - loss: 0.0967 - val_binary_accuracy: 0.9669 - val_loss: 0.0960\n",
            "Epoch 9/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9674 - loss: 0.0943 - val_binary_accuracy: 0.9672 - val_loss: 0.0942\n",
            "Epoch 10/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 129ms/step - binary_accuracy: 0.9676 - loss: 0.0926 - val_binary_accuracy: 0.9674 - val_loss: 0.0930\n",
            "Epoch 11/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9678 - loss: 0.0906 - val_binary_accuracy: 0.9677 - val_loss: 0.0909\n",
            "Epoch 12/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - binary_accuracy: 0.9684 - loss: 0.0883 - val_binary_accuracy: 0.9684 - val_loss: 0.0896\n",
            "Epoch 13/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 137ms/step - binary_accuracy: 0.9687 - loss: 0.0873 - val_binary_accuracy: 0.9683 - val_loss: 0.0898\n",
            "Epoch 14/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9690 - loss: 0.0857 - val_binary_accuracy: 0.9682 - val_loss: 0.0898\n",
            "Epoch 15/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9693 - loss: 0.0839 - val_binary_accuracy: 0.9682 - val_loss: 0.0890\n",
            "Epoch 16/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9694 - loss: 0.0830 - val_binary_accuracy: 0.9687 - val_loss: 0.0877\n",
            "Epoch 17/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 143ms/step - binary_accuracy: 0.9696 - loss: 0.0813 - val_binary_accuracy: 0.9688 - val_loss: 0.0868\n",
            "Epoch 18/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 145ms/step - binary_accuracy: 0.9701 - loss: 0.0802 - val_binary_accuracy: 0.9688 - val_loss: 0.0868\n",
            "Epoch 19/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 135ms/step - binary_accuracy: 0.9704 - loss: 0.0795 - val_binary_accuracy: 0.9685 - val_loss: 0.0868\n",
            "Epoch 20/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9704 - loss: 0.0783 - val_binary_accuracy: 0.9687 - val_loss: 0.0864\n",
            "Epoch 21/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9707 - loss: 0.0768 - val_binary_accuracy: 0.9691 - val_loss: 0.0855\n",
            "Epoch 22/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9711 - loss: 0.0759 - val_binary_accuracy: 0.9691 - val_loss: 0.0856\n",
            "Epoch 23/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 137ms/step - binary_accuracy: 0.9713 - loss: 0.0748 - val_binary_accuracy: 0.9693 - val_loss: 0.0856\n",
            "Epoch 24/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 137ms/step - binary_accuracy: 0.9714 - loss: 0.0742 - val_binary_accuracy: 0.9693 - val_loss: 0.0853\n",
            "Epoch 25/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9717 - loss: 0.0741 - val_binary_accuracy: 0.9689 - val_loss: 0.0861\n",
            "Epoch 26/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 137ms/step - binary_accuracy: 0.9717 - loss: 0.0724 - val_binary_accuracy: 0.9697 - val_loss: 0.0853\n",
            "Epoch 27/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 135ms/step - binary_accuracy: 0.9722 - loss: 0.0717 - val_binary_accuracy: 0.9697 - val_loss: 0.0853\n",
            "Epoch 28/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9726 - loss: 0.0707 - val_binary_accuracy: 0.9695 - val_loss: 0.0853\n",
            "Epoch 29/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9727 - loss: 0.0700 - val_binary_accuracy: 0.9695 - val_loss: 0.0853\n",
            "Epoch 30/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9730 - loss: 0.0694 - val_binary_accuracy: 0.9697 - val_loss: 0.0851\n",
            "Epoch 31/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 127ms/step - binary_accuracy: 0.9729 - loss: 0.0681 - val_binary_accuracy: 0.9695 - val_loss: 0.0862\n",
            "Epoch 32/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9732 - loss: 0.0672 - val_binary_accuracy: 0.9693 - val_loss: 0.0861\n",
            "Epoch 33/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9734 - loss: 0.0673 - val_binary_accuracy: 0.9695 - val_loss: 0.0871\n",
            "Epoch 34/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9737 - loss: 0.0663 - val_binary_accuracy: 0.9699 - val_loss: 0.0860\n",
            "Epoch 35/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9742 - loss: 0.0653 - val_binary_accuracy: 0.9694 - val_loss: 0.0865\n",
            "Epoch 36/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9741 - loss: 0.0640 - val_binary_accuracy: 0.9693 - val_loss: 0.0873\n",
            "Epoch 37/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9742 - loss: 0.0639 - val_binary_accuracy: 0.9696 - val_loss: 0.0869\n",
            "Epoch 38/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9745 - loss: 0.0627 - val_binary_accuracy: 0.9698 - val_loss: 0.0871\n",
            "Epoch 39/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 131ms/step - binary_accuracy: 0.9748 - loss: 0.0622 - val_binary_accuracy: 0.9695 - val_loss: 0.0885\n",
            "Epoch 40/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9750 - loss: 0.0621 - val_binary_accuracy: 0.9702 - val_loss: 0.0876\n",
            "Epoch 41/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9756 - loss: 0.0605 - val_binary_accuracy: 0.9697 - val_loss: 0.0879\n",
            "Epoch 42/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9755 - loss: 0.0604 - val_binary_accuracy: 0.9699 - val_loss: 0.0888\n",
            "Epoch 43/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9756 - loss: 0.0600 - val_binary_accuracy: 0.9694 - val_loss: 0.0898\n",
            "Epoch 44/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9760 - loss: 0.0591 - val_binary_accuracy: 0.9696 - val_loss: 0.0897\n",
            "Epoch 45/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9760 - loss: 0.0588 - val_binary_accuracy: 0.9694 - val_loss: 0.0897\n",
            "Epoch 46/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9760 - loss: 0.0599 - val_binary_accuracy: 0.9693 - val_loss: 0.0899\n",
            "Epoch 47/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - binary_accuracy: 0.9770 - loss: 0.0568 - val_binary_accuracy: 0.9696 - val_loss: 0.0906\n",
            "Epoch 48/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9770 - loss: 0.0572 - val_binary_accuracy: 0.9696 - val_loss: 0.0902\n",
            "Epoch 49/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9771 - loss: 0.0560 - val_binary_accuracy: 0.9692 - val_loss: 0.0911\n",
            "Epoch 50/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - binary_accuracy: 0.9775 - loss: 0.0548 - val_binary_accuracy: 0.9694 - val_loss: 0.0918\n",
            "Epoch 51/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9774 - loss: 0.0551 - val_binary_accuracy: 0.9690 - val_loss: 0.0917\n",
            "Epoch 52/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9778 - loss: 0.0538 - val_binary_accuracy: 0.9694 - val_loss: 0.0923\n",
            "Epoch 53/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9781 - loss: 0.0533 - val_binary_accuracy: 0.9688 - val_loss: 0.0935\n",
            "Epoch 54/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 133ms/step - binary_accuracy: 0.9784 - loss: 0.0527 - val_binary_accuracy: 0.9691 - val_loss: 0.0930\n",
            "Epoch 55/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - binary_accuracy: 0.9780 - loss: 0.0532 - val_binary_accuracy: 0.9690 - val_loss: 0.0946\n",
            "Epoch 56/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9789 - loss: 0.0515 - val_binary_accuracy: 0.9691 - val_loss: 0.0940\n",
            "Epoch 57/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9787 - loss: 0.0512 - val_binary_accuracy: 0.9690 - val_loss: 0.0951\n",
            "Epoch 58/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9792 - loss: 0.0501 - val_binary_accuracy: 0.9691 - val_loss: 0.0942\n",
            "Epoch 59/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 137ms/step - binary_accuracy: 0.9789 - loss: 0.0510 - val_binary_accuracy: 0.9691 - val_loss: 0.0938\n",
            "Epoch 60/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9795 - loss: 0.0499 - val_binary_accuracy: 0.9690 - val_loss: 0.0948\n",
            "Epoch 61/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 131ms/step - binary_accuracy: 0.9800 - loss: 0.0482 - val_binary_accuracy: 0.9685 - val_loss: 0.0961\n",
            "Epoch 62/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9802 - loss: 0.0481 - val_binary_accuracy: 0.9691 - val_loss: 0.0964\n",
            "Epoch 63/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 140ms/step - binary_accuracy: 0.9804 - loss: 0.0476 - val_binary_accuracy: 0.9683 - val_loss: 0.0984\n",
            "Epoch 64/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9794 - loss: 0.0496 - val_binary_accuracy: 0.9685 - val_loss: 0.0978\n",
            "Epoch 65/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 142ms/step - binary_accuracy: 0.9810 - loss: 0.0458 - val_binary_accuracy: 0.9689 - val_loss: 0.0986\n",
            "Epoch 66/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9808 - loss: 0.0457 - val_binary_accuracy: 0.9681 - val_loss: 0.0991\n",
            "Epoch 67/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 143ms/step - binary_accuracy: 0.9809 - loss: 0.0461 - val_binary_accuracy: 0.9682 - val_loss: 0.0994\n",
            "Epoch 68/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9805 - loss: 0.0465 - val_binary_accuracy: 0.9682 - val_loss: 0.0997\n",
            "Epoch 69/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 135ms/step - binary_accuracy: 0.9810 - loss: 0.0450 - val_binary_accuracy: 0.9681 - val_loss: 0.0999\n",
            "Epoch 70/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 140ms/step - binary_accuracy: 0.9802 - loss: 0.0483 - val_binary_accuracy: 0.9687 - val_loss: 0.1005\n",
            "Epoch 71/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9810 - loss: 0.0451 - val_binary_accuracy: 0.9687 - val_loss: 0.1004\n",
            "Epoch 72/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9817 - loss: 0.0438 - val_binary_accuracy: 0.9686 - val_loss: 0.1027\n",
            "Epoch 73/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 139ms/step - binary_accuracy: 0.9817 - loss: 0.0432 - val_binary_accuracy: 0.9686 - val_loss: 0.1017\n",
            "Epoch 74/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9821 - loss: 0.0430 - val_binary_accuracy: 0.9689 - val_loss: 0.1016\n",
            "Epoch 75/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9822 - loss: 0.0427 - val_binary_accuracy: 0.9687 - val_loss: 0.1041\n",
            "Epoch 76/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 137ms/step - binary_accuracy: 0.9826 - loss: 0.0416 - val_binary_accuracy: 0.9679 - val_loss: 0.1040\n",
            "Epoch 77/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9823 - loss: 0.0420 - val_binary_accuracy: 0.9683 - val_loss: 0.1042\n",
            "Epoch 78/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9826 - loss: 0.0414 - val_binary_accuracy: 0.9681 - val_loss: 0.1040\n",
            "Epoch 79/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 139ms/step - binary_accuracy: 0.9830 - loss: 0.0406 - val_binary_accuracy: 0.9678 - val_loss: 0.1079\n",
            "Epoch 80/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 169ms/step - binary_accuracy: 0.9833 - loss: 0.0400 - val_binary_accuracy: 0.9679 - val_loss: 0.1056\n",
            "Epoch 81/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 290ms/step - binary_accuracy: 0.9832 - loss: 0.0402 - val_binary_accuracy: 0.9675 - val_loss: 0.1057\n",
            "Epoch 82/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9832 - loss: 0.0398 - val_binary_accuracy: 0.9679 - val_loss: 0.1065\n",
            "Epoch 83/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9837 - loss: 0.0387 - val_binary_accuracy: 0.9680 - val_loss: 0.1079\n",
            "Epoch 84/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9839 - loss: 0.0390 - val_binary_accuracy: 0.9675 - val_loss: 0.1092\n",
            "Epoch 85/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 140ms/step - binary_accuracy: 0.9839 - loss: 0.0381 - val_binary_accuracy: 0.9680 - val_loss: 0.1102\n",
            "Epoch 86/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9834 - loss: 0.0391 - val_binary_accuracy: 0.9679 - val_loss: 0.1109\n",
            "Epoch 87/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 137ms/step - binary_accuracy: 0.9840 - loss: 0.0378 - val_binary_accuracy: 0.9670 - val_loss: 0.1120\n",
            "Epoch 88/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 133ms/step - binary_accuracy: 0.9841 - loss: 0.0375 - val_binary_accuracy: 0.9676 - val_loss: 0.1109\n",
            "Epoch 89/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9845 - loss: 0.0366 - val_binary_accuracy: 0.9673 - val_loss: 0.1131\n",
            "Epoch 90/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 132ms/step - binary_accuracy: 0.9846 - loss: 0.0373 - val_binary_accuracy: 0.9671 - val_loss: 0.1140\n",
            "Epoch 91/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 135ms/step - binary_accuracy: 0.9850 - loss: 0.0357 - val_binary_accuracy: 0.9673 - val_loss: 0.1137\n",
            "Epoch 92/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 129ms/step - binary_accuracy: 0.9845 - loss: 0.0368 - val_binary_accuracy: 0.9672 - val_loss: 0.1136\n",
            "Epoch 93/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9851 - loss: 0.0351 - val_binary_accuracy: 0.9678 - val_loss: 0.1141\n",
            "Epoch 94/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9851 - loss: 0.0352 - val_binary_accuracy: 0.9679 - val_loss: 0.1138\n",
            "Epoch 95/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9853 - loss: 0.0349 - val_binary_accuracy: 0.9672 - val_loss: 0.1157\n",
            "Epoch 96/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9855 - loss: 0.0345 - val_binary_accuracy: 0.9672 - val_loss: 0.1164\n",
            "Epoch 97/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - binary_accuracy: 0.9854 - loss: 0.0344 - val_binary_accuracy: 0.9674 - val_loss: 0.1151\n",
            "Epoch 98/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 131ms/step - binary_accuracy: 0.9856 - loss: 0.0344 - val_binary_accuracy: 0.9675 - val_loss: 0.1144\n",
            "Epoch 99/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 134ms/step - binary_accuracy: 0.9854 - loss: 0.0347 - val_binary_accuracy: 0.9673 - val_loss: 0.1160\n",
            "Epoch 100/100\n",
            "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 126ms/step - binary_accuracy: 0.9863 - loss: 0.0322 - val_binary_accuracy: 0.9672 - val_loss: 0.1166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as ecg_multilabel_model_tf.h5\n"
          ]
        }
      ]
    }
  ]
}